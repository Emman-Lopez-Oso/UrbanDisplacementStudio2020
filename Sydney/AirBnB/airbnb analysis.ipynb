{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import statsmodels.api as sm\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point, Polygon\n",
    "import matplotlib.pyplot as plt \n",
    "fig = plt.gcf() \n",
    "fig.set_size_inches(12, 8)\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from pathlib import Path, PureWindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File airbnb_sydney_listings.csv does not exist: 'airbnb_sydney_listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d52baa52d771>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msa2_w_dv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdv_analysis_path\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'dummies_t3_corridor.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msa2_shape16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshp_file_path\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'sa2_ucl.dbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mairbnb_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'airbnb_sydney_listings.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File airbnb_sydney_listings.csv does not exist: 'airbnb_sydney_listings.csv'"
     ]
    }
   ],
   "source": [
    "shp_file_path = Path(\"C:/Users/emman/Box/Spring 2020/Displacement Studio/Shared 228 Sydney Folder/SA2 Shapefiles\")\n",
    "dv_analysis_path =  Path(\"C:/Users/emman/Box/Spring 2020/Displacement Studio/Shared 228 Sydney Folder/AU Work/MasterTypologyFolder\")\n",
    "ab_path = Path(\"C:/Users/emman/Box/Spring 2020/Displacement Studio/Shared 228 Sydney Folder/AU Work/MasterTypologyFolder\")\n",
    "sa2_w_dv = pd.read_csv(dv_analysis_path/'dummies_t3_corridor.csv')\n",
    "sa2_shape16 = gpd.read_file(shp_file_path/'sa2_ucl.dbf').copy()\n",
    "airbnb_df = pd.read_csv('airbnb_sydney_listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(airbnb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these columns because they're either empty or probably won't be of any use\n",
    "airbnb_df.drop(['thumbnail_url','medium_url','picture_url','xl_picture_url','host_thumbnail_url',\n",
    "                'instant_bookable','require_guest_phone_verification','neighbourhood_group_cleansed',\n",
    "                'host_acceptance_rate','jurisdiction_names','host_url','host_response_time','host_response_rate',\n",
    "                'host_is_superhost','host_picture_url','host_total_listings_count','host_verifications',\n",
    "               'minimum_nights','maximum_nights','minimum_minimum_nights','maximum_minimum_nights',\n",
    "                'minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "                'maximum_nights_avg_ntm','calendar_updated','number_of_reviews','number_of_reviews_ltm',\n",
    "                'first_review','last_review','review_scores_rating','review_scores_accuracy',\n",
    "                'review_scores_cleanliness','review_scores_checkin','review_scores_communication',\n",
    "                'review_scores_location','review_scores_value',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to look at what different kinds of properties exist on airbnb and drop the ones that are not homes, \n",
    "# apartments, etc. \n",
    "airbnb_df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we propbably don't need castle, other, tent, island, train, boat, or any other of the ridiculous values that are in here. I did this line by line so \n",
    "# that if you want to add one in, all you have to do is comment out the housing type you want to keep\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Boutique hotel')] \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Bungalow')] \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Bed and breakfast')] \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Hostel')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Other')]  \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Hotel')] \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Boat')] \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Camper/RV')] \n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Aparthotel')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Farm stay')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Tent')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Earth house')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Chalet')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Island')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Barn')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Resort')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Casa particular (Cuba)')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Yurt')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Train')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Treehouse')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Castle')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Heritage hotel (India)')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Campsite')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Dome house')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Hut')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Minsu (Taiwan)')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Cave')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Tipi')]\n",
    "airbnb_df = airbnb_df[(airbnb_df.property_type != 'Casa particular')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airbnb_df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean date values to be actual dates\n",
    "airbnb_df['host_since']=pd.to_datetime(airbnb_df['host_since'])\n",
    "airbnb_df['last_scraped']=pd.to_datetime(airbnb_df['last_scraped'])\n",
    "\n",
    "# pull individual year from host_since variable\n",
    "airbnb_df['hs_year'] = pd.DatetimeIndex(airbnb_df['host_since']).year\n",
    "airbnb_df['hs_year'].dropna(inplace=True)\n",
    "airbnb_df['hs_year'].astype(int)\n",
    "\n",
    "# fill in nulls with 0 or f\n",
    "airbnb_df.bathrooms.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shapely.geometry.Point for each listing\n",
    "geometry = [Point(xy) for xy in zip(airbnb_df['longitude'], airbnb_df['latitude'])]\n",
    "crs = {'init' :'epsg:4326'}\n",
    "\n",
    "# Convert to GeoDataFrame, where each tweet's geometry is assigned to the lat/lon coords\n",
    "airbnb_gdf = gpd.GeoDataFrame(airbnb_df, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's isolate the sa2s that make up our case study areas of Redfern/Waterloo, Merrickville and Maroubra\n",
    "red_wat_gdf = sa2_shape16[(sa2_shape16.SA2_MAIN16=='117031335')\n",
    "                          |(sa2_shape16.SA2_MAIN16=='117031338')]\n",
    "\n",
    "sa2_shape16[(sa2_shape16.SA2_MAIN16=='117031335')\n",
    "                          |(sa2_shape16.SA2_MAIN16=='117031338')]\n",
    "\n",
    "# now let's create a simple rendition of the df so that we can combine its SA2 boundaries\n",
    "red_wat_simple = red_wat_gdf[['SA2_MAIN16','geometry', \"SA4_NAME16\"]].reset_index()\n",
    "\n",
    "# \"dissolve\" or \"aggregates\" all the polygons that share the same value for the variable we call\n",
    "red_wat_sgdf=red_wat_simple.dissolve(by=\"SA4_NAME16\")\n",
    "red_wat_sgdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's isolate the sa2s that make up our case study areas of Marrickville\n",
    "marr_gdf = sa2_shape16[(sa2_shape16.SA2_MAIN16=='117021326')\n",
    "                      |(sa2_shape16.SA2_MAIN16=='117021327')\n",
    "                      |(sa2_shape16.SA2_MAIN16=='117021328')\n",
    "                      |(sa2_shape16.SA2_MAIN16=='117021328')]\n",
    "\n",
    "# now let's create a simple rendition of the df so that we can combine its SA2 boundaries\n",
    "marr_simple = marr_gdf[['SA2_MAIN16','geometry', \"SA4_NAME16\"]].reset_index()\n",
    "\n",
    "# \"dissolve\" or \"aggregates\" all the polygons that share the same value for the variable we call\n",
    "marr_sgdf=marr_simple.dissolve(by=\"SA4_NAME16\")\n",
    "marr_sgdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2_w_dv['SA2_MAIN16']=sa2_w_dv['SA2_MAIN16'].astype(int)\n",
    "sa2_w_dv.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "sa2_shape16['SA2_MAIN16']=sa2_shape16['SA2_MAIN16'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2_shape16 = pd.merge(sa2_shape16,sa2_w_dv,on='SA2_MAIN16',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2_shape16 = gpd.GeoDataFrame(sa2_shape16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's isolate the sa2s that make up our case study areas of Redfern/Waterloo, Merrickville and Maroubra\n",
    "t3_corr_gdf = sa2_shape16[(sa2_shape16.t3_corr_dv==1)]\n",
    "\n",
    "# now let's create a simple rendition of the df so that we can combine its SA2 boundaries\n",
    "t3_corr_simple = t3_corr_gdf[['SA2_MAIN16','geometry', \"SA4_NAME16\"]].reset_index()\n",
    "\n",
    "# \"dissolve\" or \"aggregates\" all the polygons that share the same value for the variable we call\n",
    "t3_corr_sgdf=t3_corr_simple.dissolve(by=\"SA4_NAME16\")\n",
    "t3_corr_sgdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Density per SA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the CRS to be World Geodetic System \n",
    "sa2_shape16.crs = {'init':'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a spatial join on the UCL SA2s to find density of AirBnB listings per SA2\n",
    "list_density = gpd.sjoin(airbnb_gdf,sa2_shape16,how='right',op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the info on the new geodataframe\n",
    "list_density.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a group by statement that creates a column of the counts of listings per SA2, or in other words, count the number of geographical points that \n",
    "# fall within the boundaries of an SA2 \n",
    "list_sa2 = pd.DataFrame({'list_per_SA2' : list_density.groupby('SA2_MAIN16')['SA2_MAIN16'].count()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the count of listings by SA2 and convert it into a geodataframe so that we can create a choropleth map \n",
    "list_sa2 = pd.merge(list_sa2,sa2_shape16,on='SA2_MAIN16',how='left')\n",
    "list_sa2 = gpd.GeoDataFrame(list_sa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new variable that finds the number of listings per square kilometer \n",
    "list_sa2['listing_density'] = list_sa2.list_per_SA2/list_sa2.AREASQKM16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot geodf again with closeups \n",
    "figure, ax = plt.subplots(figsize=(14,10))\n",
    "base= list_sa2.plot(column='list_per_SA2', \n",
    "                        scheme = 'fisherjenks',\n",
    "                        legend=True,  \n",
    "                        ax=ax,\n",
    "                        cmap='Reds')\n",
    "\n",
    "red_wat_sgdf.plot(ax=base, facecolor='none', edgecolor = \"Purple\", linewidth = 1.5)\n",
    "marr_sgdf.plot(ax=base, facecolor='none', edgecolor = \"Black\", linewidth = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the number of days listings are unavailable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping by host IDs how many days out of the year, on average, are their listings available?\n",
    "h_n_list_av = pd.DataFrame(airbnb_df.groupby('property_type').agg({'availability_365':['mean','count']}))\n",
    "h_n_list_av.reset_index(inplace=True)\n",
    "h_n_list_av.columns = ['_'.join(col).strip('_') for col in h_n_list_av.columns]\n",
    "h_n_list_av.head()\n",
    "# calculate the percentage of the calendar year that these are not available for long term rentals\n",
    "h_n_list_av['pct_year'] =  round(h_n_list_av['availability_365_mean']/365,3)\n",
    "h_n_list_av.sort_values(by='availability_365_mean',ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a crosstab comparing the average number of days listings are available for Redfern/Waterloo\n",
    "pd.crosstab(list_density.property_type, list_density.red_wat_dv, values = list_density.availability_365, aggfunc=['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a crosstab comparing the average number of days listings are available for Marrickville\n",
    "pd.crosstab(list_density.property_type, list_density.marrick_dv, values = list_density.availability_365, aggfunc=['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a crosstab comparing the average number of days listings are available for Sydenham/Bankstown Corridor\n",
    "pd.crosstab(list_density.property_type, list_density.t3_corr_dv, values = list_density.availability_365, aggfunc=['mean','count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the patterns of growth for different AirBnB property types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df['count'] = 1 \n",
    "prop_year = pd.pivot_table(airbnb_df,index='property_type',columns='hs_year',values='count',aggfunc=np.sum,fill_value=0)\n",
    "prop_year.reset_index(inplace=True)\n",
    "prop_year.columns=(['property_type','2009','2010','2011','2012','2013',\n",
    "                    '2014','2015','2016','2017','2018','2019'])\n",
    "prop_year_melt = pd.melt(prop_year, \n",
    "        id_vars='property_type',\n",
    "        value_vars = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019'],\n",
    "        value_name='prop_count')\n",
    "prop_year_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "ax.set_title('Number of AirBnB Hosts Joining by Property Type, 2009-2019', fontdict={'fontsize':20})\n",
    "g = sns.lineplot(x='variable', y='prop_count', data=prop_year_melt, hue='property_type',ax=ax)\n",
    "\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Property Types')\n",
    "\n",
    "ax.annotate('Source: Inside AirBnB 2019 Scrape Sydney, AU',\n",
    "            xy=(0.1, .10),  \n",
    "            xycoords='figure fraction', \n",
    "            horizontalalignment='left', \n",
    "            verticalalignment='top', \n",
    "            fontsize=12, \n",
    "            color='#555555')\n",
    "plt.savefig('hosts_overtime_HnA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_year_melt=prop_year_melt[prop_year_melt.property_type!='Apartment']\n",
    "prop_year_melt=prop_year_melt[prop_year_melt.property_type!='House']\n",
    "\n",
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "ax.set_title('Number of AirBnB Hosts Joining by Property Type, 2009-2019', fontdict={'fontsize':20})\n",
    "g = sns.lineplot(x='variable', y='prop_count', data=prop_year_melt, hue='property_type',ax=ax)\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Property Types')\n",
    "ax.annotate('Source: Inside AirBnB 2019 Scrape Sydney, AU',\n",
    "            xy=(0.1, .10),  \n",
    "            xycoords='figure fraction', \n",
    "            horizontalalignment='left', \n",
    "            verticalalignment='top', \n",
    "            fontsize=12, \n",
    "            color='#555555')\n",
    "plt.savefig('hosts_overtime.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing trends for number of hosts that have more than one listing in AirBnB\n",
    "\n",
    "I think it's important to separate out the groups that have more than one AirBnB listing because of our stressing of how financialization of housing affects the market. In our literature review, we found that about 1/5 of Australians own more than one home. If that's the case, let's see how many times there are more than three, and then how the distribution of them look in a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Of the hosts that have >= 2 properties, how are they distributed spatially?\n",
    "\n",
    "Methodology: \n",
    "\n",
    "1. Isolate host_ids where hosts own more than 3 properties\n",
    "1. Let's work on a heatmap where the points on a map show where the distribution of properties that hosts have >= 2 listings are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = 8, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe out of a groupby that groups host IDs and counts the listing IDs in associated to them\n",
    "test_df = pd.DataFrame({'cnt_list_host' : airbnb_df.groupby('host_id')['id'].count()}).reset_index()\n",
    "# create a new geodataframe that only has listing id, host id, and geometry\n",
    "test_gdf2 = airbnb_gdf[['id','host_id','geometry']]\n",
    "# test merge \n",
    "test_merge = pd.merge(test_df,test_gdf2,on='host_id',how='left')\n",
    "# isolate new dataframe to only have listings where the count of listings per host are >=2\n",
    "#test_merge = test_merge[test_merge.cnt_list_host>=2]\n",
    "# create a new geodataframe\n",
    "tm_gdf = gpd.GeoDataFrame(test_merge, crs=crs)\n",
    "#perform a geospatial join on the new test dataframe so that we can perform this at the sa2 level\n",
    "merge_gdf = gpd.sjoin(tm_gdf,sa2_shape16,how='right',op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_gdf.dropna(inplace=True)\n",
    "merge_gdf= merge_gdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_gdf.cnt_list_host.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(14,10))\n",
    "base = sa2_shape16.plot(ax=ax)\n",
    "tm_gdf.plot(column=\"cnt_list_host\", \n",
    "              scheme = \"fisher_jenks\", \n",
    "              k = 10, \n",
    "              legend=True, \n",
    "              ax=base, \n",
    "              cmap=\"Reds\",\n",
    "             markersize=.5)\n",
    "\n",
    "t3_corr_sgdf.plot(ax=base, facecolor='none', edgecolor = \"Black\", linewidth = 1.5)\n",
    "red_wat_sgdf.plot(ax=base, facecolor='none', edgecolor = \"Purple\", linewidth = 1.5)\n",
    "\n",
    "lims=plt.axis(\"equal\")\n",
    "ax.set_axis_off()\n",
    "\n",
    "ax.set_title('Listings where Host Has >=2 Listings', fontdict={'fontsize':25})\n",
    "\n",
    "ax.annotate('Source: Inside AirBnB, 2019; Australia ABS Census Shapes, 2016',\n",
    "            xy=(0.1, .08),  \n",
    "            xycoords='figure fraction', \n",
    "            horizontalalignment='left', \n",
    "            verticalalignment='top', \n",
    "            fontsize=12, \n",
    "            color='#555555')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
