{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (clean_tweets.py, line 47)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\emman\\Documents\\git\\UrbanDisplacementStudio2020\\Sydney\\work_folder\\clean_tweets.py\"\u001b[1;36m, line \u001b[1;32m47\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       \n^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.ops import transform\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "import datetime\n",
    "\n",
    "from io import StringIO\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "# Import custom functions from `scripts` folder\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from clean_tweets import geometrize_tweets, convert_shapefile_crs, find_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometrize_tweets(df):\n",
    "    \"\"\"\n",
    "    Convert DataFrame of tweets into GeoDataFrames based on lat/lon coords.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Must contain columns 'lat' and 'lon' containing lat/lon coordinates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gpd.geodataframe.GeoDataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a shapely.geometry.Point for each tweet\n",
    "    geometry = [Point(xy) for xy in zip(df['location.lon'], df['location.lat'])]\n",
    "    crs = {'init':'epsg:4326'}\n",
    "\n",
    "    # Convert to GeoDataFrame, where each tweet's geometry is assigned to the lat/lon coords\n",
    "    return gpd.GeoDataFrame(df, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shapefile_crs(shapefile):\n",
    "    \"\"\"\n",
    "    Convert shapefile CRS to WGS84 (epsg:4326).\n",
    "    Function may take a while to run.\n",
    "    Source: https://gis.stackexchange.com/a/127432\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shapefile : geopandas.GeoDataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    shapefile : geopandas.GeoDataFrame\n",
    "        Contains updated 'geometry' column\n",
    "    \"\"\"\n",
    "    in_proj = pyproj.Proj(shapefile.crs)\n",
    "    out_proj = pyproj.Proj(init='epsg:4326')\n",
    "\n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        in_proj,\n",
    "        out_proj\n",
    "    )\n",
    "    shapefile['geometry'] = [transform(project, geom) for geom in shapefile['geometry']]\n",
    "\n",
    "    return shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequencies(series, pat, case=False, ratio=False):\n",
    "    \"\"\"\n",
    "    Find the number (or ratio) of times that a pattern occurs in a list of tweets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Column of text containing tweets. Must be dtype\n",
    "\n",
    "    pat : string\n",
    "        Regular expression to check against `series`.\n",
    "\n",
    "    case : boolean (optional, default=False)\n",
    "        If True, comparisons are case-sensitive (e.g. 'pattern' != 'PaTtErN')\n",
    "        If False, comparisons are case-insensitive. (e.g. 'pattern' == 'PaTtErN')\n",
    "\n",
    "    ratio : boolean (optional, default=False)\n",
    "        If True, return the ratio (number_of_matches) / (number_of_tweets).\n",
    "        If False, return a tuple (number_of_matches, number_of_tweets).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    integer or float\n",
    "\n",
    "    \"\"\"\n",
    "    n = len(series)\n",
    "    num_matches = series.str.contains(pat, case=case).sum()\n",
    "\n",
    "    if ratio:\n",
    "        return num_matches / n\n",
    "    else:\n",
    "        return num_matches, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_home_location(data, uid='u_id', SA2='SA2_5DIG16', date='date', hour='hour',\n",
    "                         min_tweets=10, min_days=10, min_hours=8):\n",
    "    \"\"\"\n",
    "    Assign a home location for Twitter users and their tweets based on following methodology:\n",
    "\n",
    "    1. Consider tracts satisfying the following properties:\n",
    "        - More than `min_tweets` tweets total\n",
    "        - Sent from more than `min_days` different days\n",
    "        - Sent from more than `min_hours` different hours of the day\n",
    "    2. Of the remaining candidates, select the tract with the most tweets\n",
    "\n",
    "    This function does not guarantee that all Twitter users/tweets will be assigned a home location.\n",
    "    Some users will not have any tweets that meet the criteria defined above; this will result in a\n",
    "    missing value (np.NaN) being assigned to the home tract for that user's tweets.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame or gpd.geodataframe.GeoDataFrame\n",
    "        DataFrame containing the following columns (variables passed into the function):\n",
    "            - uid : Twitter user ID\n",
    "            - sa2 : Tract identifier (e.g. tract ID, FIPS code)\n",
    "            - date : Datetime object containing just the date\n",
    "                     (year, month, and day; not a full timestamp)\n",
    "            - hour : Integer containing 24-hour-format hour of tweet\n",
    "\n",
    "    uid, tract, date, hour : string (optional, default='u_id', 'OBJECTID', 'date', 'hour')\n",
    "        Column names to extract from `data`; additional details under `data` parameter\n",
    "\n",
    "    min_tweets : integer (optional, default=10)\n",
    "        Minimum number of tweets required from a user at a valid tract\n",
    "\n",
    "    min_days : integer (optional, default=10)\n",
    "        Minimum number of unique days a user must tweet from a valid tract\n",
    "\n",
    "    min_hours : integer (optional, default=8)\n",
    "        Minimum number of unique hours a user must tweet from a valid tract\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series of length data.shape[0], containing a home location for each tweet.\n",
    "    Note that this function is not an inplace operation.\n",
    "    e.g. df['home_tract'] = assign_home_location(df)\n",
    "\n",
    "    \"\"\"\n",
    "    # Note: groupby is done multiple times to save computation time\n",
    "    home_locations = (\n",
    "        data\n",
    "        # More than min_tweets\n",
    "        .groupby(['u_id', 'SA2_5DIG16']) #will need to edit this to a different code later\n",
    "        .filter(lambda user_tract: len(user_tract) > min_tweets)\n",
    "\n",
    "        # More than min_days\n",
    "        .groupby(['u_id', 'SA2_5DIG16'])  #will need to edit this to a different code later\n",
    "        .filter(lambda user_tract: user_tract[date].nunique() > min_days)\n",
    "\n",
    "        # More than min_hours\n",
    "        .groupby(['u_id', 'SA2_5DIG16'])  #will need to edit this to a different code later\n",
    "        .filter(lambda user_tract: user_tract[hour].nunique() > min_hours)\n",
    "\n",
    "        # Extract home location\n",
    "        .groupby(['u_id', 'SA2_5DIG16'])  #will need to edit this to a different code later\n",
    "        .size()\n",
    "        .reset_index(name='count')\n",
    "        .sort_values(by='count', ascending=False)\n",
    "        .loc[:, ['u_id', 'SA2_5DIG16']]\n",
    "        .groupby('u_id')\n",
    "        .first()\n",
    "        .loc[:, 'SA2_5DIG16']\n",
    "    )\n",
    "\n",
    "    return data[uid].map(home_locations.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(data):\n",
    "    \"\"\"\n",
    "    Analyze the following:\n",
    "        - Number of tweets (printed output)\n",
    "        - Number of unique users (printed output)\n",
    "        - Median number of tweets/user (returned output)\n",
    "        - Number of tweets/user at the 99th percentile (returned output)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame or gpd.GeoDataFrame\n",
    "        DataFrame containing tweets; must contain column `u_id` for user id\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    median_tweets : int or float\n",
    "        Median number of tweets/user\n",
    "\n",
    "    pct_99_tweets : int or float\n",
    "        99th percentile of tweets/user\n",
    "    \"\"\"\n",
    "    # Number of tweets\n",
    "    print(\"{} total tweets\".format(len(data)))\n",
    "\n",
    "    # Number of unique users\n",
    "    print(\"{} unique users\\n\".format(data['u_id'].nunique()))\n",
    "\n",
    "    # Percentiles of tweets/user (median + 99th)\n",
    "    pct_50_tweets, pct_99_tweets = data.groupby('u_id').size().quantile([.50, .99])\n",
    "    print(\"Median number of tweets/user: {} tweets\".format(pct_50_tweets))\n",
    "    print(\"99th percentile of tweets/user: {} tweets\".format(pct_99_tweets))\n",
    "\n",
    "    return pct_50_tweets, pct_99_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
